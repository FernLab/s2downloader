before_script:
  - git lfs pull


stages:
  - test
  - deploy
  - cleanup


test_s2downloader:
  stage: test
  coverage: '/TOTAL\s+\d+\s+\d+\s+(\d+%)/'
  script:
    - source /root/mambaforge/bin/activate ci_env

    # install missing dependencies on the CI container
    - mamba env update --name ci_env --file tests/CI_docker/context/environment_s2downloader.yml  --prune

    # run tests
    - make pytest

    # create the docs
    - make docs

  artifacts:
    expose_as: 'Test and coverage report'
    paths:
    - htmlcov/
    - report.html
    - docs/_build/html/
    reports:
      coverage_report:
        coverage_format: cobertura
        path: coverage.xml
      junit: report.xml
    expire_in: 30 days
    when: always


test_styles:
  stage: test
  script:
    - source /root/mambaforge/bin/activate ci_env
    - make lint
  artifacts:
    paths:
    - tests/linting/flake8.log
    - tests/linting/pycodestyle.log
    - tests/linting/pydocstyle.log
    when: always


test_urls:
  stage: test
  script:
    - source /root/mambaforge/bin/activate ci_env
    - make urlcheck
  when: always


test_s2downloader_install:
  stage: test
  script:
    - source /root/mambaforge/bin/activate

    # update base environment
    - conda update -n base -c conda-forge --all

    # create s2downloader environment from environment_s2downloader.yml
    - mamba env create --name s2downloader_testinstall -f tests/CI_docker/context/environment_s2downloader.yml
    - conda activate s2downloader_testinstall

    # run installer
    - pip install .

    # check if all dependencies are correctly installed
    - pip check

    # test if its importable
    - cd ..
    - ls
    - python -c "import s2downloader; print(s2downloader)"
  only:
    - main


pages:  # this job must be called 'pages' to advise GitLab to upload content to GitLab Pages
  stage: deploy
  dependencies:
    - test_s2downloader
  script:
    # Create the public directory
    - rm -rf public
    - mkdir public
    - mkdir -p public/doc
    - mkdir -p public/doc/_static/
    - mkdir -p public/doc/docs/images
    - mkdir -p public/images/
    - mkdir -p public/coverage
    - mkdir -p public/test_reports

    # Copy over the docs
    - cp docs/index.html public/
    - cp -r docs/_static/* public/doc/_static/
    - cp -r docs/_build/html/* public/doc/
    #- cp -r docs/images/* public/images/
    #- cp -r docs/images/* public/doc/docs/images/

    # Copy over the coverage reports
    - cp -r htmlcov/* public/coverage/

    # Copy over the test reports
    - cp report.html public/test_reports/

    # Check if everything is working great
    - ls -al public
    - ls -al public/doc
    - ls -al public/coverage
    - ls -al public/test_reports
  artifacts:
    paths:
      - public
    expire_in: 30 days
  only:
    - main
